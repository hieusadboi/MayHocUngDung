import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from scipy.io import arff
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import BernoulliNB

# === 1. Load dá»¯ liá»‡u tá»« file ARFF ===
def load_data(filepath):
    data, meta = arff.loadarff(filepath)
    df = pd.DataFrame(data)
    df = df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)
    df = df.apply(pd.to_numeric, errors='coerce')
    df.dropna(inplace=True)
    return df

data_file = "Training_Dataset_Cleaned.arff"
df = load_data(data_file)

# === 2. TÃ¡ch táº­p dá»¯ liá»‡u ===
X = df.drop(columns=["Result"])
y = df["Result"]

# === 3. Chia train / test (70% train, 30% test) ===
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ============================
#  ğŸ”¹ MÃ´ hÃ¬nh CÃ¢y Quyáº¿t Äá»‹nh
# ============================
dt_model = DecisionTreeClassifier(criterion='gini', max_depth=9, random_state=42)
dt_model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n
y_pred_dt = dt_model.predict(X_test)

# ÄÃ¡nh giÃ¡
accuracy_dt = accuracy_score(y_test, y_pred_dt)
cm_dt = confusion_matrix(y_test, y_pred_dt)

print(f"ğŸ”¹ Äá»™ chÃ­nh xÃ¡c Decision Tree: {accuracy_dt:.2f}")
print("ğŸ“Œ Ma tráº­n nháº§m láº«n (Decision Tree):\n", cm_dt)

# LÆ°u mÃ´ hÃ¬nh
joblib.dump(dt_model, "decision_tree_model.pkl")

# === Váº½ cÃ¢y quyáº¿t Ä‘á»‹nh ===
plt.figure(figsize=(35, 15))
plot_tree(dt_model, filled=True, feature_names=X.columns, class_names=["KhÃ´ng lá»«a Ä‘áº£o", "Lá»«a Ä‘áº£o"], fontsize=8)
plt.savefig("decision_tree.png", dpi=300)

# ============================
#  ğŸ”¹ MÃ´ hÃ¬nh KNN
# ============================
k_values = range(1, 30)
accuracies = []

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k, metric='hamming')
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    accuracies.append(acc)

# XÃ¡c Ä‘á»‹nh k tá»‘i Æ°u
best_k = k_values[np.argmax(accuracies)]
knn_best = KNeighborsClassifier(n_neighbors=best_k, metric='hamming')
knn_best.fit(X_train, y_train)
y_pred_knn = knn_best.predict(X_test)

# ÄÃ¡nh giÃ¡ KNN
accuracy_knn = accuracy_score(y_test, y_pred_knn)
cm_knn = confusion_matrix(y_test, y_pred_knn)

print(f"ğŸ”¹ Äá»™ chÃ­nh xÃ¡c KNN (k={best_k}): {accuracy_knn:.2f}")
print("ğŸ“Œ Ma tráº­n nháº§m láº«n (KNN):\n", cm_knn)

# LÆ°u mÃ´ hÃ¬nh KNN
joblib.dump(knn_best, "knn_model.pkl")

# === Váº½ biá»ƒu Ä‘á»“ Ä‘á»™ chÃ­nh xÃ¡c theo K ===
plt.figure(figsize=(20, 10))
plt.plot(k_values, accuracies, marker='o', linestyle='dashed', color='b', label="Äá»™ chÃ­nh xÃ¡c KNN")
plt.axvline(x=best_k, color='r', linestyle='--', label=f"K tá»‘i Æ°u ({best_k})")
plt.xlabel("Sá»‘ hÃ ng xÃ³m (k)")
plt.ylabel("Äá»™ chÃ­nh xÃ¡c")
plt.title("Chá»n k tá»‘i Æ°u cho thuáº­t toÃ¡n KNN")
plt.legend()
plt.grid(True)
plt.savefig("knn_accuracy.png", dpi=300)

# ============================
#  ğŸ”¹ MÃ´ hÃ¬nh Naive Bayes
# ============================
nb_model = BernoulliNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)

# ÄÃ¡nh giÃ¡ Naive Bayes
accuracy_nb = accuracy_score(y_test, y_pred_nb)
cm_nb = confusion_matrix(y_test, y_pred_nb)

print(f"ğŸ”¹ Äá»™ chÃ­nh xÃ¡c Naive Bayes: {accuracy_nb:.2f}")
print("ğŸ“Œ Ma tráº­n nháº§m láº«n (Naive Bayes):\n", cm_nb)

# LÆ°u mÃ´ hÃ¬nh Naive Bayes
joblib.dump(nb_model, "naive_bayes_model.pkl")

# Váº½ vÃ  lÆ°u ma tráº­n nháº§m láº«n cho Decision Tree
plt.figure(figsize=(10, 8))
sns.heatmap(cm_dt, annot=True, fmt="d", cmap="Blues", xticklabels=["KhÃ´ng lá»«a Ä‘áº£o", "Lá»«a Ä‘áº£o"], 
            yticklabels=["KhÃ´ng lá»«a Ä‘áº£o", "Lá»«a Ä‘áº£o"])
plt.title("Ma tráº­n nháº§m láº«n - Decision Tree")
plt.xlabel("GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n")
plt.ylabel("GiÃ¡ trá»‹ thá»±c táº¿")
plt.savefig("confusion_matrix_decision_tree.png", dpi=300)

# Váº½ vÃ  lÆ°u ma tráº­n nháº§m láº«n cho KNN
plt.figure(figsize=(10, 8))
sns.heatmap(cm_knn, annot=True, fmt="d", cmap="Greens", xticklabels=["KhÃ´ng lá»«a Ä‘áº£o", "Lá»«a Ä‘áº£o"], 
            yticklabels=["KhÃ´ng lá»«a Ä‘áº£o", "Lá»«a Ä‘áº£o"])
plt.title(f"Ma tráº­n nháº§m láº«n - KNN (k={best_k})")
plt.xlabel("GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n")
plt.ylabel("GiÃ¡ trá»‹ thá»±c táº¿")
plt.savefig("confusion_matrix_knn.png", dpi=300)

# Váº½ vÃ  lÆ°u ma tráº­n nháº§m láº«n cho Naive Bayes
plt.figure(figsize=(10, 8))
sns.heatmap(cm_nb, annot=True, fmt="d", cmap="Oranges", xticklabels=["KhÃ´ng lá»«a Ä‘áº£o", "Lá»«a Ä‘áº£o"], 
            yticklabels=["KhÃ´ng lá»«a Ä‘áº£o", "Lá»«a Ä‘áº£o"])
plt.title("Ma tráº­n nháº§m láº«n - Naive Bayes")
plt.xlabel("GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n")
plt.ylabel("GiÃ¡ trá»‹ thá»±c táº¿")
plt.savefig("confusion_matrix_naive_bayes.png", dpi=300)

# Váº½ táº¥t cáº£ 3 ma tráº­n
plt.show()

